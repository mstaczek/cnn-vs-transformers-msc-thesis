{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../codes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.strings_to_classes_mappings import models_mapping\n",
    "# models_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/convnextv2_nano.fcmae_ft_in22k_in1k_384\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/deit_small_patch16_224.fb_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/deit_tiny_patch16_224.fb_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/densenet121.tv_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/efficientnet_b3.ra2_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/efficientnet_b4.ra2_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/mobilenetv3_large_100.ra_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/pvt_v2_b2.in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/res2net50_14w_8s.in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/resnet18d.ra2_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/resnet50d.ra2_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/resnext50_32x4d.a1h_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/swin_tiny_patch4_window7_224.ms_in1k\n",
      "Loaded default imagenet-pretrained model: https://huggingface.co/timm/vit_base_patch32_224.augreg_in21k_ft_in1k\n"
     ]
    }
   ],
   "source": [
    "import src.models\n",
    "\n",
    "# create a dict with model names as keys, and a tuple of model instance and layer to be used for GradCAM as values\n",
    "models_with_gradcam_layers = {}\n",
    "model = src.models.ConvNeXtV2_Nano().get_model(); models_with_gradcam_layers['ConvNeXtV2_Nano'] = (model, [model.norm_pre])\n",
    "model = src.models.DeiT_S().get_model(); models_with_gradcam_layers['DeiT_S'] = (model, [model.blocks[-1].norm1])\n",
    "model = src.models.DeiT_T().get_model(); models_with_gradcam_layers['DeiT_T'] = (model, [model.blocks[-1].norm1])\n",
    "model = src.models.DenseNet121().get_model(); models_with_gradcam_layers['DenseNet121'] = (model, [model.features])\n",
    "model = src.models.EfficientNet_B3().get_model(); models_with_gradcam_layers['EfficientNet_B3'] = (model, [model.conv_head])\n",
    "model = src.models.EfficientNet_B4().get_model(); models_with_gradcam_layers['EfficientNet_B4'] = (model, [model.conv_head])\n",
    "model = src.models.MobileNetV3().get_model(); models_with_gradcam_layers['MobileNetV3'] = (model, [model.blocks])\n",
    "model = src.models.PyramidViT_V2_B2().get_model(); models_with_gradcam_layers['PyramidViT_V2_B2'] = (model, [model.stages[-1].blocks[-1]])\n",
    "model = src.models.Res2Net50().get_model(); models_with_gradcam_layers['Res2Net50'] = (model, [model.layer4[-1]])\n",
    "model = src.models.ResNet18().get_model(); models_with_gradcam_layers['ResNet18'] = (model, [model.layer4[-1]])\n",
    "model = src.models.ResNet50().get_model(); models_with_gradcam_layers['ResNet50'] = (model, [model.layer4[-1]])\n",
    "model = src.models.ResNeXt50().get_model(); models_with_gradcam_layers['ResNeXt50'] = (model, [model.layer4[-1]])\n",
    "model = src.models.Swin_T().get_model(); models_with_gradcam_layers['Swin_T'] = (model, [model.layers[-1].blocks[-1]])\n",
    "model = src.models.ViT_B_32().get_model(); models_with_gradcam_layers['ViT_B_32'] = (model, [model.blocks[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXtV2_Nano\n",
      "\t torch.Size([640, 7, 7])\n",
      "DeiT_S\n",
      "\t torch.Size([197, 384])\n",
      "DeiT_T\n",
      "\t torch.Size([197, 192])\n",
      "DenseNet121\n",
      "\t torch.Size([1024, 7, 7])\n",
      "EfficientNet_B3\n",
      "\t torch.Size([1536, 7, 7])\n",
      "EfficientNet_B4\n",
      "\t torch.Size([1792, 7, 7])\n",
      "MobileNetV3\n",
      "\t torch.Size([960, 7, 7])\n",
      "PyramidViT_V2_B2\n",
      "\t torch.Size([49, 512])\n",
      "Res2Net50\n",
      "\t torch.Size([2048, 7, 7])\n",
      "ResNet18\n",
      "\t torch.Size([512, 7, 7])\n",
      "ResNet50\n",
      "\t torch.Size([2048, 7, 7])\n",
      "ResNeXt50\n",
      "\t torch.Size([2048, 7, 7])\n",
      "Swin_T\n",
      "\t torch.Size([7, 7, 768])\n",
      "ViT_B_32\n",
      "\t torch.Size([50, 768])\n"
     ]
    }
   ],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "import torch\n",
    "\n",
    "def print_gradcam_layer_size(model, target_layer):\n",
    "    def print_tensor_size(tensor):\n",
    "        print('\\t',tensor.size()[1:])\n",
    "        return None\n",
    "\n",
    "    input_tensor = torch.randn(2, 3, 224, 224)\n",
    "    try:\n",
    "        from pytorch_grad_cam import GradCAM\n",
    "        gradcam_explanation_method = GradCAM(model=model, target_layers=target_layer, reshape_transform=print_tensor_size)\n",
    "        explanation = gradcam_explanation_method(input_tensor=input_tensor)[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for model_name, (model, target_layer) in models_with_gradcam_layers.items():\n",
    "    print(model_name)\n",
    "    print_gradcam_layer_size(model, target_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis-cnn-vs-transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
